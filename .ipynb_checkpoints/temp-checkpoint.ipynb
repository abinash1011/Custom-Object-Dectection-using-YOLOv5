{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9.5.0\n"
     ]
    }
   ],
   "source": [
    "import PIL\n",
    "print(PIL.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import random\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/ashutosh/.cache/torch/hub/ultralytics_yolov5_master\n",
      "YOLOv5 üöÄ 2023-8-5 Python-3.10.0 torch-2.0.1+cu117 CPU\n",
      "\n",
      "Fusing layers... \n",
      "YOLOv5s summary: 213 layers, 7225885 parameters, 0 gradients\n",
      "Adding AutoShape... \n"
     ]
    }
   ],
   "source": [
    "model = torch.hub.load('ultralytics/yolov5', 'yolov5s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('img.jpg', <http.client.HTTPMessage at 0x7fc7fb8568f0>)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import urllib.request\n",
    "urllib.request.urlretrieve('https://blog.finxter.com/wp-content/uploads/2022/04/greenland_01a.jpg',\"img.jpg\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = \"img.jpg\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 360x640 7 persons, 1 boat\n",
      "Speed: 8.1ms pre-process, 94.5ms inference, 1.3ms NMS per image at shape (1, 3, 384, 640)\n"
     ]
    }
   ],
   "source": [
    "results = model(img)\n",
    "results.print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mweights=yolov5s.pt, cfg=, data=/home/ashutosh/work/od/yolov5/data/dataset.yaml, hyp=data/hyps/hyp.scratch-low.yaml, epochs=50, batch_size=16, imgsz=640, rect=False, resume=False, nosave=False, noval=False, noautoanchor=False, noplots=False, evolve=None, bucket=, cache=None, image_weights=False, device=, multi_scale=False, single_cls=False, optimizer=SGD, sync_bn=False, workers=8, project=runs/train, name=exp, exist_ok=False, quad=False, cos_lr=False, label_smoothing=0.0, patience=100, freeze=[0], save_period=-1, seed=0, local_rank=-1, entity=None, upload_dataset=False, bbox_interval=-1, artifact_alias=latest\n",
      "remote: Enumerating objects: 4, done.\u001b[K\n",
      "remote: Counting objects: 100% (4/4), done.\u001b[K\n",
      "remote: Compressing objects: 100% (3/3), done.\u001b[K\n",
      "Unpacking objects: 100% (4/4), 2.27 KiB | 2.27 MiB/s, done.\n",
      "remote: Total 4 (delta 1), reused 3 (delta 1), pack-reused 0\u001b[K\n",
      "From https://github.com/ultralytics/yolov5\n",
      "   2270f0d..0897415  master     -> origin/master\n",
      "\u001b[34m\u001b[1mgithub: \u001b[0m‚ö†Ô∏è YOLOv5 is out of date by 5 commits. Use 'git pull' or 'git clone https://github.com/ultralytics/yolov5' to update.\n",
      "YOLOv5 üöÄ v7.0-198-g34c2187 Python-3.10.0 torch-2.0.1+cu117 CPU\n",
      "\n",
      "\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=0.05, cls=0.5, cls_pw=1.0, obj=1.0, obj_pw=1.0, iou_t=0.2, anchor_t=4.0, fl_gamma=0.0, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0\n",
      "\u001b[34m\u001b[1mComet: \u001b[0mrun 'pip install comet_ml' to automatically track and visualize YOLOv5 üöÄ runs in Comet\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/train', view at http://localhost:6006/\n",
      "Overriding model.yaml nc=80 with nc=21\n",
      "\n",
      "                 from  n    params  module                                  arguments                     \n",
      "  0                -1  1      3520  models.common.Conv                      [3, 32, 6, 2, 2]              \n",
      "  1                -1  1     18560  models.common.Conv                      [32, 64, 3, 2]                \n",
      "  2                -1  1     18816  models.common.C3                        [64, 64, 1]                   \n",
      "  3                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               \n",
      "  4                -1  2    115712  models.common.C3                        [128, 128, 2]                 \n",
      "  5                -1  1    295424  models.common.Conv                      [128, 256, 3, 2]              \n",
      "  6                -1  3    625152  models.common.C3                        [256, 256, 3]                 \n",
      "  7                -1  1   1180672  models.common.Conv                      [256, 512, 3, 2]              \n",
      "  8                -1  1   1182720  models.common.C3                        [512, 512, 1]                 \n",
      "  9                -1  1    656896  models.common.SPPF                      [512, 512, 5]                 \n",
      " 10                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
      " 11                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
      " 12           [-1, 6]  1         0  models.common.Concat                    [1]                           \n",
      " 13                -1  1    361984  models.common.C3                        [512, 256, 1, False]          \n",
      " 14                -1  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
      " 15                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
      " 16           [-1, 4]  1         0  models.common.Concat                    [1]                           \n",
      " 17                -1  1     90880  models.common.C3                        [256, 128, 1, False]          \n",
      " 18                -1  1    147712  models.common.Conv                      [128, 128, 3, 2]              \n",
      " 19          [-1, 14]  1         0  models.common.Concat                    [1]                           \n",
      " 20                -1  1    296448  models.common.C3                        [256, 256, 1, False]          \n",
      " 21                -1  1    590336  models.common.Conv                      [256, 256, 3, 2]              \n",
      " 22          [-1, 10]  1         0  models.common.Concat                    [1]                           \n",
      " 23                -1  1   1182720  models.common.C3                        [512, 512, 1, False]          \n",
      " 24      [17, 20, 23]  1     70122  models.yolo.Detect                      [21, [[10, 13, 16, 30, 33, 23], [30, 61, 62, 45, 59, 119], [116, 90, 156, 198, 373, 326]], [128, 256, 512]]\n",
      "Model summary: 214 layers, 7076266 parameters, 7076266 gradients, 16.1 GFLOPs\n",
      "\n",
      "Transferred 343/349 items from yolov5s.pt\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01) with parameter groups 57 weight(decay=0.0), 60 weight(decay=0.0005), 60 bias\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /home/ashutosh/work/od/data/labels.cache... 124 images, 0 backgr\u001b[0m\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ‚ö†Ô∏è /home/ashutosh/work/od/data/images/ble18.jpg: corrupt JPEG restored and saved\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ‚ö†Ô∏è /home/ashutosh/work/od/data/images/stm3.jpg: corrupt JPEG restored and saved\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /home/ashutosh/work/od/data/labels.cache... 124 images, 0 backgrou\u001b[0m\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ‚ö†Ô∏è /home/ashutosh/work/od/data/images/ble18.jpg: corrupt JPEG restored and saved\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ‚ö†Ô∏è /home/ashutosh/work/od/data/images/stm3.jpg: corrupt JPEG restored and saved\n",
      "\n",
      "\u001b[34m\u001b[1mAutoAnchor: \u001b[0m3.27 anchors/target, 1.000 Best Possible Recall (BPR). Current anchors are a good fit to dataset ‚úÖ\n",
      "Plotting labels to runs/train/exp6/labels.jpg... \n",
      "Image sizes 640 train, 640 val\n",
      "Using 8 dataloader workers\n",
      "Logging results to \u001b[1mruns/train/exp6\u001b[0m\n",
      "Starting training for 50 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "       0/49         0G     0.1244    0.02942    0.08413         28        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   WARNING ‚ö†Ô∏è NMS time limit 2.100s exceeded\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all        124        136    0.00186     0.0749    0.00109     0.0005\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "       1/49         0G      0.111     0.0299    0.08502         37        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all        124        136    0.00195      0.131    0.00138   0.000531\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "       2/49         0G    0.09712    0.03021    0.07992         34        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all        124        136    0.00354      0.253    0.00316   0.000892\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "       3/49         0G     0.0882    0.02989    0.07624         33        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all        124        136    0.00685      0.433    0.00659     0.0016\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "       4/49         0G    0.07838    0.02875     0.0684         27        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all        124        136    0.00844      0.671     0.0174    0.00552\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "       5/49         0G    0.06965    0.03061    0.06481         38        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all        124        136     0.0098      0.922     0.0789     0.0274\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "       6/49         0G    0.06261    0.02778    0.06155         34        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all        124        136    0.00804      0.946      0.106     0.0421\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "       7/49         0G    0.06545    0.02611    0.05927         34        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all        124        136     0.0282      0.215      0.067     0.0221\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "       8/49         0G    0.06054    0.02464    0.05283         36        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all        124        136      0.295      0.282      0.149     0.0486\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "       9/49         0G    0.06191    0.02257    0.05631         30        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all        124        136      0.104      0.317      0.102     0.0348\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      10/49         0G    0.06401    0.02316    0.05027         36        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all        124        136      0.196      0.373      0.166     0.0637\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      11/49         0G     0.0673    0.02146    0.04967         34        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all        124        136      0.129      0.263      0.124     0.0536\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      12/49         0G    0.05729     0.0206    0.05087         25        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all        124        136      0.177      0.274      0.172     0.0671\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      13/49         0G    0.06464    0.02053    0.04539         28        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all        124        136      0.283      0.279      0.259      0.129\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      14/49         0G    0.05924    0.02218     0.0426         31        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all        124        136      0.302      0.332      0.296      0.166\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      15/49         0G    0.05876    0.02039    0.04163         29        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all        124        136      0.298      0.326      0.319      0.178\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      16/49         0G    0.05347    0.01683     0.0401         27        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all        124        136      0.292       0.31       0.33      0.153\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      17/49         0G     0.0528    0.01735    0.04184         33        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all        124        136      0.288      0.334      0.329      0.182\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      18/49         0G    0.04969    0.02002    0.04249         36        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all        124        136      0.364      0.525      0.419       0.24\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      19/49         0G    0.05223    0.01959     0.0401         33        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all        124        136      0.421      0.531      0.446      0.232\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      20/49         0G    0.05244     0.0184    0.03896         34        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all        124        136      0.406      0.535      0.455      0.242\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      21/49         0G    0.05014    0.01823    0.03751         32        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all        124        136      0.382      0.575      0.458      0.243\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      22/49         0G    0.04582     0.0182    0.04113         39        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all        124        136      0.539      0.523      0.559      0.336\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      23/49         0G     0.0458    0.01595    0.03539         29        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all        124        136      0.525      0.588      0.599      0.361\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      24/49         0G    0.04218    0.01605     0.0354         28        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all        124        136      0.546      0.586      0.614      0.398\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      25/49         0G    0.04703    0.01599    0.03396         29        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all        124        136      0.515      0.613      0.565      0.349\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      26/49         0G    0.04281    0.01685    0.03396         40        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all        124        136      0.623      0.597      0.669      0.433\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      27/49         0G    0.04193    0.01641    0.03453         37        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all        124        136      0.626      0.584       0.67      0.459\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      28/49         0G    0.04327    0.01652    0.03289         27        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all        124        136      0.623      0.621      0.704      0.488\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      29/49         0G    0.03876    0.01651    0.03587         31        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all        124        136      0.684      0.673      0.739      0.521\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      30/49         0G    0.03741    0.01531    0.03149         36        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all        124        136      0.695      0.675      0.741      0.491\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      31/49         0G    0.03813    0.01503    0.03255         25        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all        124        136      0.723       0.72      0.786      0.564\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      32/49         0G    0.03819    0.01543     0.0287         31        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all        124        136      0.826      0.706      0.819      0.588\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      33/49         0G    0.03488    0.01413    0.02777         30        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all        124        136      0.825      0.781      0.845       0.62\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      34/49         0G     0.0383    0.01419    0.02735         31        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all        124        136      0.836      0.765      0.858      0.644\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      35/49         0G    0.03344    0.01469    0.03082         32        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all        124        136      0.794      0.739      0.852      0.599\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      36/49         0G    0.03422    0.01433    0.02731         33        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all        124        136      0.801      0.768      0.877      0.651\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      37/49         0G    0.03368    0.01364    0.03053         30        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all        124        136       0.85      0.771      0.895      0.683\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      38/49         0G    0.03185    0.01314    0.02583         34        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all        124        136      0.854      0.799      0.898      0.686\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      39/49         0G    0.03346    0.01426    0.02398         38        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all        124        136      0.872      0.823       0.91      0.678\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      40/49         0G     0.0312     0.0153    0.02685         37        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all        124        136      0.934      0.816      0.914      0.701\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      41/49         0G    0.03249    0.01291    0.02288         29        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all        124        136      0.942       0.82      0.918      0.723\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      42/49         0G    0.03059    0.01383    0.02511         36        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all        124        136      0.942      0.847      0.924      0.719\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      43/49         0G     0.0311    0.01445    0.02393         31        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all        124        136      0.945      0.861      0.937      0.734\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      44/49         0G    0.02614    0.01315    0.02136         26        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all        124        136      0.953      0.875      0.947      0.749\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      45/49         0G    0.02831    0.01298    0.02027         35        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all        124        136      0.959       0.88      0.958      0.766\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      46/49         0G    0.02933     0.0129     0.0216         30        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all        124        136      0.956       0.89      0.965      0.784\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      47/49         0G    0.03232    0.01359    0.02284         30        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all        124        136       0.91      0.916      0.969      0.795\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      48/49         0G    0.02617    0.01348    0.01941         45        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all        124        136      0.919      0.911      0.969       0.79\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      49/49         0G    0.02682    0.01258    0.01926         34        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all        124        136      0.917      0.922       0.97      0.792\n",
      "\n",
      "50 epochs completed in 0.529 hours.\n",
      "Optimizer stripped from runs/train/exp6/weights/last.pt, 14.5MB\n",
      "Optimizer stripped from runs/train/exp6/weights/best.pt, 14.5MB\n",
      "\n",
      "Validating runs/train/exp6/weights/best.pt...\n",
      "Fusing layers... \n",
      "Model summary: 157 layers, 7066762 parameters, 0 gradients, 15.9 GFLOPs\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all        124        136       0.91      0.915      0.969      0.795\n",
      "           Arduino Uno        124         28      0.933      0.993      0.993      0.812\n",
      "Arduino Nano BLE Sense        124         23      0.739       0.87      0.933      0.711\n",
      "                ESP 32        124         21      0.934      0.671      0.907       0.76\n",
      "    Nvidia Jetson Nano        124         23      0.941          1      0.992      0.805\n",
      "          Raspberry Pi        124         24      0.959      0.958      0.993      0.827\n",
      "          STM32 Nucleo        124         17      0.956          1      0.995      0.855\n",
      "Results saved to \u001b[1mruns/train/exp6\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!cd yolov5 && python train.py --img 640 --epochs 50 --data /home/ashutosh/work/od/yolov5/data/dataset.yaml --weights yolov5s.pt --workers 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://github.com/ultralytics/yolov5/zipball/master\" to /home/ashutosh/.cache/torch/hub/master.zip\n",
      "YOLOv5 üöÄ 2023-8-5 Python-3.10.0 torch-2.0.1+cu117 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 157 layers, 7066762 parameters, 0 gradients, 15.9 GFLOPs\n",
      "Adding AutoShape... \n"
     ]
    }
   ],
   "source": [
    "model = torch.hub.load('ultralytics/yolov5', 'custom', path='yolov5/runs/train/exp6/weights/last.pt', force_reload=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_random_file_paths(directory, num_files):\n",
    "    file_list = [os.path.join(directory, file) for file in os.listdir(directory) if os.path.isfile(os.path.join(directory, file))]\n",
    "    if not file_list:\n",
    "        raise ValueError(\"No files found in the directory.\")\n",
    "\n",
    "    return random.sample(file_list, num_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 471x690 1 ESP 32\n",
      "Speed: 11.6ms pre-process, 64.4ms inference, 0.8ms NMS per image at shape (1, 3, 448, 640)\n"
     ]
    }
   ],
   "source": [
    "test_img = \"test_esp32_@.png\"\n",
    "# test_img = get_random_file_paths(\"data/images/\", 1)\n",
    "\n",
    "test_img = test_img if type(test_img) == str else test_img[0]\n",
    "\n",
    "results = model(test_img)\n",
    "results.print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plt.imshow(np.squeeze(results.render()))\n",
    "plt.title(test_img[0].split(\"/\")[-1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_images_per_row = 6\n",
    "num_rows = 6\n",
    "\n",
    "directory_path = \"data/images/\"\n",
    "random_file_paths = get_random_file_paths(directory_path, num_images_per_row * num_rows)\n",
    "\n",
    "fig, axes = plt.subplots(num_rows, num_images_per_row, figsize=(12, 12))\n",
    "\n",
    "for i, file_path in enumerate(random_file_paths):\n",
    "    results = model(file_path)\n",
    "    ax = axes[i // num_images_per_row, i % num_images_per_row]\n",
    "    ax.imshow(np.squeeze(results.render()))\n",
    "    ax.set_title(file_path.split(\"/\")[-1])\n",
    "    ax.axis(\"off\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://github.com/ultralytics/yolov5/zipball/master\" to /home/ashutosh/.cache/torch/hub/master.zip\n",
      "YOLOv5 üöÄ 2023-8-5 Python-3.10.0 torch-2.0.1+cu117 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 157 layers, 7066762 parameters, 0 gradients, 15.9 GFLOPs\n",
      "Adding AutoShape... \n"
     ]
    }
   ],
   "source": [
    "model2 = torch.hub.load('ultralytics/yolov5', 'custom', path='yolov5/runs/train/exp6/weights/best.pt', force_reload=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "other_od",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
